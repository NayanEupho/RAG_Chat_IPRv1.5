# RAG Chat IPR - Configuration File
# Rename this or create a new file named .env to enable "Zero-click" startup

# 1. Main Chat Model (Inference)
RAG_MAIN_HOST="http://localhost:11434"
RAG_MAIN_MODEL="llama3"

# 2. RAG Embedding Model (Vectorization)
RAG_EMBED_HOST="http://localhost:11434"
RAG_EMBED_MODEL="nomic-embed-text"

# 3. RAG Workflow Strategy (Architecture)
# Options: "fused" (72B+, Fast, One-Shot) or "modular" (7B+, Stable, Sequential)
RAG_WORKFLOW="fused"

# 4. VLM OCR Model (Vision-Language Model for PDF Extraction)
# Set RAG_VLM_MODEL="False" to disable VLM OCR (uses Docling instead)
# Set to model name like "deepseek-ocr:3b" to enable VLM-based extraction
# Requires: pymupdf package installed
RAG_VLM_HOST="http://localhost:11434"
RAG_VLM_MODEL="False"

# 5. VLM Prompt Strategy (How the VLM processes documents)
# Options:
#   "auto"         - (Default) Smart two-pass: Pass 1 extracts document structure,
#                    Pass 2 auto-detects unlabeled images/diagrams and describes them.
#                    Best balance of speed and accuracy.
#
#   "grounding"    - Single-pass with grounding prompt. Extracts document to markdown
#                    preserving tables, figures, and structure. Fastest option.
#                    Use for well-structured documents with labeled visuals.
#
#   "describe"     - Single-pass with description prompt. Describes ALL images in detail.
#                    Slowest but most thorough for image-heavy documents.
#                    Use for photo albums, diagrams without text, visual reports.
#
#   "parse_figure" - Single-pass for parsing figures/charts specifically.
#                    Use for documents that are primarily charts/graphs.
RAG_VLM_PROMPT="auto"
